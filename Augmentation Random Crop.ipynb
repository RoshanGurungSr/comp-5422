{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80c9986a-cc6d-4efc-90fd-96cff6e800d8",
   "metadata": {},
   "source": [
    "#### **Data Augmentation using random cropping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828411eb-7f37-4a67-9201-f06029cba60e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import Augmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07d29e3-5a83-4996-aa49-e0d421f4a5f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Average image file per object = 1350\n",
    "def augument_crop(data_dir, label, out_dir, num_transformation=1):\n",
    "    data_fp = os.path.join(data_dir, label)\n",
    "    out_fp = os.path.join(out_dir, label)\n",
    "    \n",
    "    aug_pipeline = Augmentor.Pipeline(source_directory=data_fp, output_directory=out_fp)\n",
    "    aug_pipeline.crop_random(probability=0.5, percentage_area=0.3)\n",
    "    num_of_samples = int(20)\n",
    "    \n",
    "    aug_pipeline.sample(num_of_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433007e8-045f-4d13-850b-da74c154d43e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folder_names = ['cassette_player', 'chain_saw', 'church', 'english_springer', 'french_horn', 'garbage_truck', 'gas_pump', 'golf_ball', 'parachute', 'tench']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8566ab-f2ba-4c5e-8828-28ce2b47abad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = \"dataset/\"\n",
    "out_dir = os.path.join(os.getcwd(), \"dataset_crop_random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f29a68-f5c3-458e-9028-d8f63a468841",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for folder_name in folder_names:\n",
    "    augument_horizontal_crop(data_dir=data_dir, label=folder_name, out_dir=out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0b2bb5-52c0-4768-be11-2f9c556754dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "299b8ab7-74a1-4281-966f-0e94149dca2b",
   "metadata": {},
   "source": [
    "#### **Mapping the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28643448-ed38-457d-8986-4e882217029a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os import walk\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3785ad-f71b-4155-8077-86906a38022d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "current_dir = os.path.abspath(os.getcwd())\n",
    "data_path = \"dataset_crop_random/\" # Change the mapping directory\n",
    "data_mapping = []\n",
    "\n",
    "for (dirpath, dirnames, filenames) in walk(data_path):\n",
    "    if filenames:\n",
    "        label_name = dirpath.split(\"/\")[-1]\n",
    "        data_full_fp = [os.path.join(current_dir, dirpath, fname) for fname in filenames]\n",
    "        \n",
    "        for data_fp in data_full_fp:\n",
    "            data_mapping.append([data_fp, label_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78b64b5-c3e3-488b-9fe6-82154f545376",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(data_mapping, columns=[\"filename\", \"label\"])\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaf4675-9b9d-47db-9af5-322ad2bf652b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels_map = {\n",
    "    'cassette_player': 0,\n",
    "    'chain_saw': 1,\n",
    "    'church': 2,\n",
    "    'english_springer': 3,\n",
    "    'french_horn': 4,\n",
    "    'garbage_truck': 5,\n",
    "    'gas_pump': 6,\n",
    "    'golf_ball': 7,\n",
    "    'parachute': 8,\n",
    "    'tench': 9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41e5afd-1511-4d3e-b943-e97d3c5e5df7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(data_df, \n",
    "                               test_size=0.2, \n",
    "                               stratify=data_df[\"label\"], \n",
    "                               random_state=42)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e7aa69-0a5b-4687-ac37-ff451a0d6053",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.to_csv(os.path.join(data_path, \"train.csv\"), index=False)\n",
    "test.to_csv(os.path.join(data_path, \"test.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b6bb1c-c5ec-4219-a3d5-ed299f8a77f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11923824-5dc8-445d-9a1f-a77a7eddcb72",
   "metadata": {},
   "source": [
    "#### **Modelling Using the Augmentated Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b50c330-c9c0-4b61-971b-45aa007d8287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ca994b-5fbc-4aac-aec2-e4949bb2a5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, labels_map, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_labels['label'] = self.img_labels['label'].map(labels_map)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_labels.iloc[idx, 0]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        label = torch.tensor(int(self.img_labels.iloc[idx, 1]), dtype=torch.uint8)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb06b498-6298-4705-9a68-a085767ad6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ResNetModel, self).__init__()\n",
    "        self.resnet18 = models.resnet18(pretrained=False)\n",
    "        self.resnet18.fc = nn.Linear(in_features=512, out_features=num_classes)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.resnet18(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e56abb-0989-46fb-84a1-f7d00074de74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dir(dir_name):\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "        \n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228f65ed-142c-43ed-9317-b74ba0b307cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dump_model(training_id, model_dir, model):\n",
    "    model_name = f\"{training_id}_resnet18_od.pth\"\n",
    "    create_dir(dir_name=model_dir)\n",
    "        \n",
    "    model_dump_fp = os.path.join(model_dir, model_name)\n",
    "    torch.save(model.state_dict(), model_dump_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93090493-3afa-4a2a-8807-ae293dd587fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels_map = {\n",
    "    'cassette_player': 0,\n",
    "    'chain_saw': 1,\n",
    "    'church': 2,\n",
    "    'english_springer': 3,\n",
    "    'french_horn': 4,\n",
    "    'garbage_truck': 5,\n",
    "    'gas_pump': 6,\n",
    "    'golf_ball': 7,\n",
    "    'parachute': 8,\n",
    "    'tench': 9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b252b98c-825f-470a-a17a-a60b40d86f8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_annotation_fp = \"dataset_90_rotation/train.csv\"\n",
    "test_annotation_fp = \"dataset_90_rotation/test.csv\"\n",
    "\n",
    "model_dir = \"./models\"\n",
    "training_id = f\"random_crop_{datetime.utcnow().timestamp()}\" #change the training id\n",
    "\n",
    "log_dir = os.path.join(\"./log_dir\", training_id)\n",
    "create_dir(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed0d86e-6563-468a-b36f-cdb63acae643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet-18 expects input images of size (224, 224)\n",
    "feature_transform = transforms.Compose([\n",
    "    transforms.Resize(size=(224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = CustomImageDataset(annotations_file=train_annotation_fp, \n",
    "                                   labels_map=labels_map,\n",
    "                                   transform=feature_transform,\n",
    "                                  )\n",
    "test_dataset = CustomImageDataset(annotations_file=test_annotation_fp, \n",
    "                                  labels_map=labels_map,\n",
    "                                  transform=feature_transform,\n",
    "                                 )\n",
    "\n",
    "# Define the DataLoader\n",
    "batch_size = 16\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb13a73-1b59-448e-9913-cba1313bb3a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbbbdc1-d864-4d92-8d9e-1e55a92d1ce2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plotting some image samples from the dataloaders\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    train_features, train_labels = next(iter(train_dataloader))\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_features[0].numpy().transpose((1, 2, 0)))\n",
    "    plt.xlabel(train_labels[0].tolist())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf7ef48-7973-442c-b774-52085d74e091",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "num_class = 10\n",
    "learning_rate = 1e-03\n",
    "num_epoch = 20\n",
    "save_model = True\n",
    "\n",
    "model = ResNetModel(num_classes=num_class)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aa7639-0b72-44d7-8038-99beee7951aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.train()\n",
    "model.to(device)\n",
    "\n",
    "epoch_ls, total_loss, total_accuracy = [], [], []\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "\n",
    "    loss_train, acc_train = 0, 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # calculate the loss and accuracy\n",
    "        loss_train += loss.item()\n",
    "        \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        acc_train += (predicted == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    epoch_loss = loss_train / len(train_dataloader)\n",
    "    epoch_accuracy = acc_train / total_samples\n",
    "    \n",
    "    epoch_ls.append(epoch)\n",
    "    total_loss.append(epoch_loss)\n",
    "    total_accuracy.append(epoch_accuracy)\n",
    "    \n",
    "    print(f\"Current epoch: {epoch} | Training Accuracy: {epoch_accuracy} | Training Loss: {epoch_loss}\")\n",
    "    \n",
    "if save_model:\n",
    "    dump_model(training_id, model_dir, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95185b1-e710-4fad-bf6d-bf0110d70d22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "test_acc = 100 * correct // total\n",
    "print(f'Test Accuracy: {test_acc}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8bf01c-f614-4ff5-a727-5473737fea95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_metrics_df = pd.DataFrame(zip(epoch_ls, total_loss, total_accuracy), columns=[\"epoch\", \"loss\", \"accuracy\"])\n",
    "train_metrics_df.to_csv(f\"{os.path.join(log_dir, 'training_metrics.csv')}\", index=False)\n",
    "train_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6636e0f-93c4-4918-831c-fd1da20d7350",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_acc = 100 * correct // total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164a54ab-7ef1-4cff-95ae-ab943484e914",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_metrics_df = pd.DataFrame([test_acc], columns=[\"accuracy\"])\n",
    "test_metrics_df.to_csv(f\"{os.path.join(log_dir, 'test_metrics.csv')}\", index=False)\n",
    "test_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9e63c4-140f-4cfa-8986-5cafccf17d88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.lineplot(data=pd.melt(train_metrics_df, [\"epoch\"]), x=\"epoch\", y=\"value\", hue=\"variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a178281-dcf2-42bc-89b1-fa4c4aa86a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244c18ff-eb36-4e03-9f74-977d891bc221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "735216a2-1c22-434c-92fd-c7e46c68713a",
   "metadata": {},
   "source": [
    "### Deprecated Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8099457-f2df-4a24-a3c7-bddc8c7c4872",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# img = train_features[0].numpy().transpose((1, 2, 0))\n",
    "# label = train_labels[0]\n",
    "# plt.imshow(img)\n",
    "# plt.show()\n",
    "# print(f\"Label: {label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jarvis",
   "language": "python",
   "name": "jarvis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
